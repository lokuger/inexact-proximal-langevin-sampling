import numpy as npfrom numpy.random import default_rngimport otclass MYULA():    def __init__(self, max_iter, tau, gamma, x0, pd):        # we're computing samples in self.x with shape (d, n_samples)        # expect input x0 to be (d, n_samples) as well        self.max_iter = max_iter        self.iter = 0        self.tau = tau        self.gamma = gamma        self.d, self.n_samples = x0.shape        self.x0 = np.copy(x0)        self.x = np.copy(x0)        self.dF = pd.F.grad        self.proxG = pd.G.prox        self.rng = default_rng()            def update(self):        self.iter = self.iter + 1        xi = self.rng.normal(loc=0, scale=1, size=(self.d, self.n_samples))        self.x = ((1-self.tau/self.gamma) * self.x            - self.tau * self.dF(self.x)            + self.tau/self.gamma * self.proxG(self.x, gamma=self.gamma)            + np.sqrt(2*self.tau) * xi)            def simulate(self, x_comp = None, return_all = False):        return_errs = False        if x_comp is not None:            assert(x_comp.shape[0]==self.x.shape[0],'Comparison samples must have the same dimension as running samples')            return_errs = True            W2dist = np.zeros((self.max_iter+1,))            W2dist[0] = ot.emd2_1d(np.reshape(self.x0,(-1,)), np.reshape(x_comp,(-1,)))        if return_all:            x_all = np.zeros((self.d, self.n_samples, self.max_iter+1))            x_all[:,:,0] = self.x0                    while self.iter < self.max_iter:            self.update()            if return_all:                x_all[:,:,self.iter] = self.x            if return_errs:                W2dist[self.iter] = ot.emd2_1d(np.reshape(self.x,(-1,)), np.reshape(x_comp,(-1,)))                x_return = x_all if return_all else self.x        if return_errs:            return x_return, W2dist        else:            return x_return                